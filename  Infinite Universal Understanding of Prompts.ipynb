{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b68590f-dfed-480e-a081-f4e6fa1ebadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai  # Replace with Hugging Face Transformers if needed\n",
    "from typing import Dict, Any\n",
    "\n",
    "# Step 1: Define the NLP Query Interpreter\n",
    "def interpret_prompt(prompt: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Interpret the user prompt into actionable instructions for the VAISEC IR model.\n",
    "    \"\"\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=f\"Interpret this IR model prompt and output actions:\\nPrompt: {prompt}\\nActions:\",\n",
    "        max_tokens=150,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    try:\n",
    "        actions = eval(response['choices'][0]['text'].strip())  # Unsafe in production, sanitize in real-world\n",
    "    except Exception as e:\n",
    "        print(\"Error parsing response:\", e)\n",
    "        actions = {\"error\": str(e)}\n",
    "    return actions\n",
    "\n",
    "# Step 2: Define the VAISEC IR Model\n",
    "class VAISECIRModel:\n",
    "    def __init__(self):\n",
    "        self.latent_dim = 128\n",
    "        self.learning_rate = 0.001\n",
    "        self.diversity_penalty = 0.5\n",
    "        self.retrieval_threshold = 0.8\n",
    "        self.temperature = 1.0\n",
    "        self.index = []  # Simulated IR index\n",
    "\n",
    "    def update_parameters(self, parameters: Dict[str, Any]):\n",
    "        \"\"\"\n",
    "        Dynamically update model parameters based on interpreted actions.\n",
    "        \"\"\"\n",
    "        for param, value in parameters.items():\n",
    "            if hasattr(self, param):\n",
    "                setattr(self, param, value)\n",
    "                print(f\"Updated {param} to {value}\")\n",
    "            else:\n",
    "                print(f\"Unknown parameter '{param}', ignoring.\")\n",
    "\n",
    "    def perform_retrieval(self, query: str):\n",
    "        \"\"\"\n",
    "        Simulated retrieval based on the model's parameters.\n",
    "        \"\"\"\n",
    "        print(f\"Performing retrieval with threshold {self.retrieval_threshold} and diversity {self.diversity_penalty}...\")\n",
    "        results = [f\"Document {i}\" for i in range(1, 6)]  # Placeholder\n",
    "        return results\n",
    "\n",
    "# Step 3: Main Loop for Infinite Prompt Understanding\n",
    "if __name__ == \"__main__\":\n",
    "    model = VAISECIRModel()\n",
    "    print(\"Initial Model Configuration:\", model.__dict__)\n",
    "    \n",
    "    while True:\n",
    "        # Get the user prompt\n",
    "        prompt = input(\"\\nEnter a universal prompt for the IR model (or 'exit' to quit): \")\n",
    "        if prompt.lower() == \"exit\":\n",
    "            break\n",
    "\n",
    "        # Step 1: Interpret the prompt\n",
    "        actions = interpret_prompt(prompt)\n",
    "        print(\"Interpreted Actions:\", actions)\n",
    "        \n",
    "        # Step 2: Update the model parameters if applicable\n",
    "        if \"parameters\" in actions:\n",
    "            model.update_parameters(actions[\"parameters\"])\n",
    "        \n",
    "        # Step 3: Perform IR tasks if requested\n",
    "        if \"query\" in actions:\n",
    "            results = model.perform_retrieval(actions[\"query\"])\n",
    "            print(\"Retrieved Results:\", results)\n",
    "\n",
    "        print(\"Updated Model Configuration:\", model.__dict__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6e5df4-c400-4862-b717-872589f72514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai  # Or replace with Hugging Face Transformers if needed\n",
    "from typing import Dict, Any\n",
    "\n",
    "# Step 1: Define the NLP Prompt Interpreter\n",
    "def interpret_prompt(prompt: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Interpret the user prompt into actionable instructions for the VAISEC IR model.\n",
    "    \"\"\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",  # Use a large model for diverse understanding\n",
    "        prompt=f\"\"\"\n",
    "        Interpret this user prompt and map it to actionable tasks for an information retrieval system:\n",
    "        - Identify parameters to adjust in the system.\n",
    "        - Specify if external data or APIs are needed.\n",
    "        - Provide fallback clarifications if ambiguous.\n",
    "        \n",
    "        User Prompt: {prompt}\n",
    "        Actions (parameters, external_data, clarifications):\n",
    "        \"\"\",\n",
    "        max_tokens=200,\n",
    "        temperature=0.8,\n",
    "    )\n",
    "    try:\n",
    "        actions = eval(response['choices'][0]['text'].strip())  # Unsafe for production, sanitize in real-world\n",
    "    except Exception as e:\n",
    "        print(\"Error parsing response:\", e)\n",
    "        actions = {\"error\": str(e)}\n",
    "    return actions\n",
    "\n",
    "# Step 2: Define the VAISEC IR Model with Dynamic Expansion\n",
    "class VAISECIRModel:\n",
    "    def __init__(self):\n",
    "        self.latent_dim = 128\n",
    "        self.learning_rate = 0.001\n",
    "        self.diversity_penalty = 0.5\n",
    "        self.retrieval_threshold = 0.8\n",
    "        self.temperature = 1.0\n",
    "        self.custom_parameters = {}  # Allow dynamic addition of new parameters\n",
    "        self.index = []  # Simulated IR index\n",
    "\n",
    "    def update_parameters(self, parameters: Dict[str, Any]):\n",
    "        \"\"\"\n",
    "        Dynamically update model parameters based on interpreted actions.\n",
    "        \"\"\"\n",
    "        for param, value in parameters.items():\n",
    "            if hasattr(self, param):\n",
    "                setattr(self, param, value)\n",
    "                print(f\"Updated {param} to {value}\")\n",
    "            else:\n",
    "                self.custom_parameters[param] = value  # Add custom parameters dynamically\n",
    "                print(f\"Added custom parameter '{param}' with value {value}\")\n",
    "\n",
    "    def perform_retrieval(self, query: str):\n",
    "        \"\"\"\n",
    "        Simulated retrieval based on the model's parameters.\n",
    "        \"\"\"\n",
    "        print(f\"Performing retrieval with parameters: {self.retrieval_threshold}, {self.diversity_penalty}, {self.custom_parameters}...\")\n",
    "        results = [f\"Document {i}\" for i in range(1, 6)]  # Placeholder\n",
    "        return results\n",
    "\n",
    "# Step 3: External Data Integration\n",
    "def fetch_external_data(source: str) -> Any:\n",
    "    \"\"\"\n",
    "    Fetch data from external APIs or sources if specified in the prompt.\n",
    "    \"\"\"\n",
    "    if source == \"weather\":\n",
    "        # Example: Fetch weather data\n",
    "        return {\"weather\": \"sunny\", \"temperature\": 25}\n",
    "    elif source == \"news\":\n",
    "        # Example: Fetch recent news\n",
    "        return {\"news\": [\"Headline 1\", \"Headline 2\", \"Headline 3\"]}\n",
    "    else:\n",
    "        return {\"error\": f\"Unknown external data source '{source}'\"}\n",
    "\n",
    "# Step 4: Main Loop for Infinite Prompt Understanding\n",
    "if __name__ == \"__main__\":\n",
    "    model = VAISECIRModel()\n",
    "    print(\"Initial Model Configuration:\", model.__dict__)\n",
    "    \n",
    "    while True:\n",
    "        prompt = input(\"\\nEnter a universal prompt for the IR model (or 'exit' to quit): \")\n",
    "        if prompt.lower() == \"exit\":\n",
    "            break\n",
    "\n",
    "        # Step 1: Interpret the prompt\n",
    "        actions = interpret_prompt(prompt)\n",
    "        print(\"Interpreted Actions:\", actions)\n",
    "        \n",
    "        # Step 2: Fetch external data if specified\n",
    "        if \"external_data\" in actions:\n",
    "            external_data = fetch_external_data(actions[\"external_data\"])\n",
    "            print(\"Fetched External Data:\", external_data)\n",
    "        \n",
    "        # Step 3: Update the model parameters if applicable\n",
    "        if \"parameters\" in actions:\n",
    "            model.update_parameters(actions[\"parameters\"])\n",
    "        \n",
    "        # Step 4: Perform IR tasks if requested\n",
    "        if \"query\" in actions:\n",
    "            results = model.perform_retrieval(actions[\"query\"])\n",
    "            print(\"Retrieved Results:\", results)\n",
    "\n",
    "        print(\"Updated Model Configuration:\", model.__dict__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69d7bb08-c58a-4ef7-94f5-f4209e4fbdb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flowchart saved as flowchart.png\n"
     ]
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "# Create a directed graph\n",
    "dot = Digraph(format='png', graph_attr={'rankdir': 'TB'})\n",
    "\n",
    "# Nodes\n",
    "# Step 1: Initialization\n",
    "dot.node('Start', 'Start Program', shape='ellipse', style='filled', color='lightblue')\n",
    "dot.node('Init', 'Initialize VAISEC IR Model', shape='box')\n",
    "\n",
    "# Step 2: Interpret Prompt\n",
    "dot.node('Prompt', 'User Inputs Prompt', shape='parallelogram')\n",
    "dot.node('Interpret', 'Interpret Prompt', shape='box')\n",
    "dot.node('Actions', 'Actions Parsed', shape='parallelogram')\n",
    "\n",
    "# Step 3: External Data Integration\n",
    "dot.node('FetchData?', 'External Data Specified?', shape='diamond')\n",
    "dot.node('FetchData', 'Fetch External Data', shape='box')\n",
    "dot.node('NoData', 'Skip Data Fetch', shape='ellipse')\n",
    "\n",
    "# Step 4: Update Parameters\n",
    "dot.node('Params?', 'Parameters to Update?', shape='diamond')\n",
    "dot.node('UpdateParams', 'Update Model Parameters', shape='box')\n",
    "dot.node('NoUpdate', 'Skip Parameter Update', shape='ellipse')\n",
    "\n",
    "# Step 5: Perform Retrieval\n",
    "dot.node('Query?', 'Query Specified?', shape='diamond')\n",
    "dot.node('Retrieve', 'Perform Retrieval Task', shape='box')\n",
    "dot.node('NoRetrieve', 'Skip Retrieval', shape='ellipse')\n",
    "\n",
    "# Loop or Exit\n",
    "dot.node('Exit?', 'User Input: Exit?', shape='diamond')\n",
    "dot.node('End', 'End Program', shape='ellipse', style='filled', color='lightgrey')\n",
    "\n",
    "# Edges\n",
    "# Initialization\n",
    "dot.edge('Start', 'Init')\n",
    "dot.edge('Init', 'Prompt')\n",
    "\n",
    "# Interpret Prompt\n",
    "dot.edge('Prompt', 'Interpret')\n",
    "dot.edge('Interpret', 'Actions')\n",
    "\n",
    "dot.edge('Actions', 'FetchData?')\n",
    "dot.edge('FetchData?', 'FetchData', label='Yes')\n",
    "dot.edge('FetchData?', 'NoData', label='No')\n",
    "dot.edge('FetchData', 'Params?')\n",
    "dot.edge('NoData', 'Params?')\n",
    "\n",
    "dot.edge('Params?', 'UpdateParams', label='Yes')\n",
    "dot.edge('Params?', 'NoUpdate', label='No')\n",
    "dot.edge('UpdateParams', 'Query?')\n",
    "dot.edge('NoUpdate', 'Query?')\n",
    "\n",
    "dot.edge('Query?', 'Retrieve', label='Yes')\n",
    "dot.edge('Query?', 'NoRetrieve', label='No')\n",
    "dot.edge('Retrieve', 'Exit?')\n",
    "dot.edge('NoRetrieve', 'Exit?')\n",
    "dot.edge('Exit?', 'End', label='Yes')\n",
    "dot.edge('Exit?', 'Prompt', label='No')\n",
    "\n",
    "# Save the flowchart to a file\n",
    "dot.render('from graphviz import Digraph\n",
    "\n",
    "# Create a directed graph\n",
    "dot = Digraph(format='png', graph_attr={'rankdir': 'LR'})\n",
    "\n",
    "# Nodes\n",
    "# Step 1: Initialization\n",
    "dot.node('Start', 'Start Program', shape='ellipse', style='filled', color='lightblue')\n",
    "dot.node('Init', 'Initialize VAISEC IR Model', shape='box')\n",
    "\n",
    "# Step 2: Interpret Prompt\n",
    "dot.node('Prompt', 'User Inputs Prompt', shape='parallelogram')\n",
    "dot.node('Interpret', 'Interpret Prompt', shape='box')\n",
    "dot.node('Actions', 'Actions Parsed', shape='parallelogram')\n",
    "\n",
    "# Step 3: External Data Integration\n",
    "dot.node('FetchData?', 'External Data Specified?', shape='diamond')\n",
    "dot.node('FetchData', 'Fetch External Data', shape='box')\n",
    "dot.node('NoData', 'Skip Data Fetch', shape='ellipse')\n",
    "\n",
    "# Step 4: Update Parameters\n",
    "dot.node('Params?', 'Parameters to Update?', shape='diamond')\n",
    "dot.node('UpdateParams', 'Update Model Parameters', shape='box')\n",
    "dot.node('NoUpdate', 'Skip Parameter Update', shape='ellipse')\n",
    "\n",
    "# Step 5: Perform Retrieval\n",
    "dot.node('Query?', 'Query Specified?', shape='diamond')\n",
    "dot.node('Retrieve', 'Perform Retrieval Task', shape='box')\n",
    "dot.node('NoRetrieve', 'Skip Retrieval', shape='ellipse')\n",
    "\n",
    "# Loop or Exit\n",
    "dot.node('Exit?', 'User Input: Exit?', shape='diamond')\n",
    "dot.node('End', 'End Program', shape='ellipse', style='filled', color='lightgrey')\n",
    "\n",
    "# Edges\n",
    "# Initialization\n",
    "dot.edge('Start', 'Init')\n",
    "dot.edge('Init', 'Prompt')\n",
    "\n",
    "# Interpret Prompt\n",
    "dot.edge('Prompt', 'Interpret')\n",
    "dot.edge('Interpret', 'Actions')\n",
    "\n",
    "dot.edge('Actions', 'FetchData?')\n",
    "dot.edge('FetchData?', 'FetchData', label='Yes')\n",
    "dot.edge('FetchData?', 'NoData', label='No')\n",
    "dot.edge('FetchData', 'Params?')\n",
    "dot.edge('NoData', 'Params?')\n",
    "\n",
    "dot.edge('Params?', 'UpdateParams', label='Yes')\n",
    "dot.edge('Params?', 'NoUpdate', label='No')\n",
    "dot.edge('UpdateParams', 'Query?')\n",
    "dot.edge('NoUpdate', 'Query?')\n",
    "\n",
    "dot.edge('Query?', 'Retrieve', label='Yes')\n",
    "dot.edge('Query?', 'NoRetrieve', label='No')\n",
    "dot.edge('Retrieve', 'Exit?')\n",
    "dot.edge('NoRetrieve', 'Exit?')\n",
    "dot.edge('Exit?', 'End', label='Yes')\n",
    "dot.edge('Exit?', 'Prompt', label='No')\n",
    "\n",
    "# Save the flowchart to a file\n",
    "dot.render('/mnt/data/flowchart', format='png', cleanup=False)\n",
    "\n",
    "print(\"Flowchart saved as flowchart.png\")\n",
    "flowchart', format='png', cleanup=False)\n",
    "\n",
    "print(\"Flowchart saved as flowchart_2.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ec5d14-843b-4a8e-8746-05b2961eb0f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b37e2038-ddee-455a-9958-fcd76410da7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flowchart saved as flowchart.png\n"
     ]
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "# Create a directed graph\n",
    "dot = Digraph(format='png', graph_attr={'rankdir': 'LR'})\n",
    "\n",
    "# Nodes\n",
    "# Step 1: Initialization\n",
    "dot.node('Start', 'Start Program', shape='ellipse', style='filled', color='lightblue')\n",
    "dot.node('Init', 'Initialize VAISEC IR Model', shape='box')\n",
    "\n",
    "# Step 2: Interpret Prompt\n",
    "dot.node('Prompt', 'User Inputs Prompt', shape='parallelogram')\n",
    "dot.node('Interpret', 'Interpret Prompt', shape='box')\n",
    "dot.node('Actions', 'Actions Parsed', shape='parallelogram')\n",
    "\n",
    "# Step 3: Update Parameters\n",
    "dot.node('Params?', 'Parameters to Update?', shape='diamond')\n",
    "dot.node('UpdateParams', 'Update Model Parameters', shape='box')\n",
    "dot.node('NoUpdate', 'Skip Parameter Update', shape='ellipse')\n",
    "\n",
    "# Step 4: Perform Retrieval\n",
    "dot.node('Query?', 'Query Specified?', shape='diamond')\n",
    "dot.node('Retrieve', 'Perform Retrieval Task', shape='box')\n",
    "dot.node('NoRetrieve', 'Skip Retrieval', shape='ellipse')\n",
    "\n",
    "# Loop or Exit\n",
    "dot.node('Exit?', 'User Input: Exit?', shape='diamond')\n",
    "dot.node('End', 'End Program', shape='ellipse', style='filled', color='lightgrey')\n",
    "\n",
    "# Edges\n",
    "# Initialization\n",
    "dot.edge('Start', 'Init')\n",
    "dot.edge('Init', 'Prompt')\n",
    "\n",
    "# Interpret Prompt\n",
    "dot.edge('Prompt', 'Interpret')\n",
    "dot.edge('Interpret', 'Actions')\n",
    "\n",
    "dot.edge('Actions', 'Params?')\n",
    "\n",
    "dot.edge('Params?', 'UpdateParams', label='Yes')\n",
    "dot.edge('Params?', 'NoUpdate', label='No')\n",
    "dot.edge('UpdateParams', 'Query?')\n",
    "dot.edge('NoUpdate', 'Query?')\n",
    "\n",
    "dot.edge('Query?', 'Retrieve', label='Yes')\n",
    "dot.edge('Query?', 'NoRetrieve', label='No')\n",
    "dot.edge('Retrieve', 'Exit?')\n",
    "dot.edge('NoRetrieve', 'Exit?')\n",
    "dot.edge('Exit?', 'End', label='Yes')\n",
    "dot.edge('Exit?', 'Prompt', label='No')\n",
    "\n",
    "# Save the flowchart to a file\n",
    "dot.render('lowchart', format='png', cleanup=False)\n",
    "\n",
    "print(\"Flowchart saved as flowchart.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3181ef6-8d2f-48c3-b9d4-c144d75d77a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flowchart saved as flowcharfgf.png\n"
     ]
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "# Create a directed graph\n",
    "dot = Digraph(format='png', graph_attr={'rankdir': 'LR'})\n",
    "\n",
    "# Nodes\n",
    "# Step 1: Initialization\n",
    "dot.node('Start', 'Start Program', shape='ellipse', style='filled', color='lightblue')\n",
    "dot.node('Prompt', 'User Inputs Prompt', shape='parallelogram')\n",
    "dot.node('End', 'End Program', shape='ellipse', style='filled', color='lightgrey')\n",
    "\n",
    "# Edges\n",
    "# Simplified Flow\n",
    "dot.edge('Start', 'Prompt')\n",
    "dot.edge('Prompt', 'End')\n",
    "\n",
    "# Save the flowchart to a file\n",
    "dot.render('flowchart', format='png', cleanup=False)\n",
    "\n",
    "print(\"Flowchart saved as flowcharfgf.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "459e2094-ad8e-4658-a398-67c6f879f60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as flowchart.png\n"
     ]
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "# Create a directed graph\n",
    "dot = Digraph(format='png', graph_attr={'rankdir': 'LR'})\n",
    "\n",
    "# Nodes\n",
    "# Step 1: Initialization\n",
    "dot.node('Start', 'Start Program', shape='ellipse', style='filled', color='lightblue')\n",
    "dot.node('Init', 'Initialize Model', shape='box')\n",
    "dot.node('Prompt', 'User Inputs Prompt', shape='parallelogram')\n",
    "dot.node('Interpret', 'Interpret Prompt', shape='box')\n",
    "dot.node('Query', 'Perform Retrieval Task', shape='box')\n",
    "dot.node('End', 'End Program', shape='ellipse', style='filled', color='lightgrey')\n",
    "\n",
    "# Edges\n",
    "# Simplified Flow with 5-7 Blocks\n",
    "dot.edge('Start', 'Init')\n",
    "dot.edge('Init', 'Prompt')\n",
    "dot.edge('Prompt', 'Interpret')\n",
    "dot.edge('Interpret', 'Query')\n",
    "dot.edge('Query', 'End')\n",
    "\n",
    "# Save the flowchart to a file\n",
    "dot.render('lowchart', format='png', cleanup=False)\n",
    "\n",
    "print(\"saved as flowchart.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc5a734a-4b89-47f3-879e-551b575e548a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10_year_treasury_yield.png\n",
      " 1_bubble.png\n",
      "'1 vaisec IR correct heatmap.png'\n",
      " 1_vasicek_interest_rate_simulation_with_gan_realistic.png\n",
      " 2_adjusted_vasicek_interest_rate_simulation.png\n",
      "'2 cek Model with VAE Latent Feature.png'\n",
      " 2_gan_data_distribution.png\n",
      "'2_venn of technologies.png'\n",
      "'3 3D Surface of Simulated Interest Rates.png'\n",
      "'3D Latent Space of Interest Rates (VAE).png'\n",
      " 3_headmaps_topic.png\n",
      "'4 Density Plot of Initial Interest Rates.png'\n",
      " 4_Heat_map_applicationschart_2025-01-18_18-48-26.png\n",
      "'5 Simulated Interest Rate Paths ut.png'\n",
      "'Actual vs. Reconstructed Interest Rates(VAE).png'\n",
      " ai_finance_method_tree_simple.png.png\n",
      " ai_finance_method_tree_with_citations.png.png\n",
      " ai_finance_method_tree_with_corrected_colors.png.png\n",
      " ai_finance_method_tree_with_fixed_colors.png.png\n",
      " ai_finance_method_tree_with_more_papers_v2.png.png\n",
      " ai_finance_paper_heatmap_v2.png\n",
      " ai_finance_venn_diagram_adjusted.png\n",
      " ai_finance_venn_diagram_explained.png\n",
      " ai_finance_venn_diagram.png\n",
      " ai_risk_management_venn_diagram.png\n",
      " ai_risk_management_venn_diagram_updated.png\n",
      " app.py\n",
      " automobile-loan-default-classification.ipynb\n",
      " bank_logo_with_clean_stripes.png\n",
      " bank_logo_with_corner_stripes.png\n",
      " bank_logo_with_faded_stripes.png\n",
      " bank_logo_with_stripes.png\n",
      "'big data gen ai charting.ipynb'\n",
      " chart_2025-01-18_18-48-20.png\n",
      " chart_2025-01-18_18-48-36.png\n",
      " chat_saved_logistic_regression_model.ipynb\n",
      " citation_network_fixed.png\n",
      " citation_network_good.png\n",
      " citation_network_next_5.png\n",
      " citation_network_next_5_zoomed_fixed.png\n",
      " citation_network_next_5_zoomed.png\n",
      " citation_network.png\n",
      " citation_network_top_5.png\n",
      " citation_network_top_5_zoomed_fixed.png\n",
      " citation_network_top_5_zoomed.png\n",
      " citation_network_top_7_adjusted_final.png\n",
      " citation_network_top_7_adjusted.png\n",
      " citation_network_top_7.png\n",
      "'code to do it yourself.ipynb'\n",
      "'DALL·E 2025-01-20 01.18.49 - A minimalistic flowchart diagram in plain, simple style with boxes and arrows only. The flowchart shows six steps_ (1) Input Universal Prompt, (2) Int.webp'\n",
      " default_prediction_model.pkl\n",
      "'Distribution of Initial Rates (VAE Output).png'\n",
      "'Distribution of Initial Rates VAE Output.png'\n",
      " fine-tuned_DistilBERT_prod.ipynb\n",
      " FineTuningBERTLogistic_light_v4_cleaned_working_prod.ipynb\n",
      " FineTuningBERTLogistic_light_v5_cleaned_working_prod.ipynb\n",
      " flowchart\n",
      " flowchart.png\n",
      " gan2.ipynb\n",
      " GAN.ipynb\n",
      " gan_v3.ipynb\n",
      " gan_v4.ipynb\n",
      " gan_v5_prod.ipynb\n",
      " gan_v6_prod.ipynb\n",
      " gan_v7.ipynb\n",
      " gan_v8.ipynb\n",
      " gan_violin_plot.png\n",
      "'hugging face.ipynb'\n",
      " Improved_Interest_Rates_vs_Latent_Factors.png\n",
      "' Infinite Universal Understanding of Prompts.ipynb'\n",
      "'Interest Rates vs Latent Factors Over Time.png'\n",
      " itation_network_top_5.png\n",
      " kaggle.ipynb\n",
      "'Latent Factor 1 2 Distribution.png'\n",
      "'Latent Space of Interest Rates 1.png'\n",
      "'Latent Space of Interest Rates (VAE) with Color Gradient 1.png'\n",
      " literature_review_chart.png\n",
      " logistic_model.py\n",
      " logo.ipynb\n",
      " lowchart\n",
      " lowchart.png\n",
      " map_instructions_prod.ipynb\n",
      " my_local_model\n",
      " older_files\n",
      "'open ai example gen ai finance v2.ipynb'\n",
      " output_images\n",
      " prompts\n",
      " __pycache__\n",
      "'radar charts gen ai in finance.ipynb'\n",
      " README.md\n",
      " real_vs_generated_data_2.png\n",
      " real_vs_generated_data_4.png\n",
      " real_vs_generated_data_6.png\n",
      " real_vs_generated_data_7.png\n",
      " real_vs_generated_data.png\n",
      " requirements.txt\n",
      " results\n",
      " sentiment.ipynb\n",
      " Simulated_Interest_Rate_Paths.mp4\n",
      " submission.csv\n",
      " torch.ipynb\n",
      " trained_model\n",
      " TTBB_BERT_vs_GPT.ipynb\n",
      " twitter_buzz.ipynb\n",
      " vae.ipynb\n",
      " vae_v2_prod.ipynb\n",
      " vae_v3_prod.ipynb\n",
      " vae_v4_prod.ipynb\n",
      " vae_v5_prod.ipynb\n",
      "'vai vaisec.ipynb'\n",
      " vasicek_correlation_heatmap.png\n",
      " vasicek_interest_rate_bokeh.html\n",
      " vasicek_interest_rate_simulation_with_gan.png\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b6b415-c155-48e4-99c1-3c8ff64e7b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
